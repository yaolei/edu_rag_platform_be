from typing import Optional, List, Dict
from fastapi import UploadFile
import asyncio
import time
import json
from pathlib import Path
from service_rag.app.embedding.embedding_data import EmbeddingData
from service_rag.app.prompt.prompt import prompt_setting
from langchain_core.documents import Document
from service_rag.app.document_operation.document_loader import DocumentLoader
from service_rag.app.text_splitter.text_split import TextSplitter
from service_rag.app.vector.vector_store import VectorStore
from service_rag.app.llm_model.contect_llm import  connect_text_llm, analyze_with_image, stream_llm_response
from service_rag.app.text_splitter.advanced_text_cleaner import AdvancedTextCleaner
from service_rag.app.service.gen_util import build_simple_context, prue_image_chunks

class RagService:
    def __init__(self):
        self.embedding_type = None
        self.upload_file = None
        self.file_name = None
        self.target_file = None
        self.embeddings = None
        self.vector = None
        self.question = None
        self.file_type = None
        self.if_files = None
        self.doc_type = None
        self.mutil_files = []

        self.image_binary_data = None
        self.conversation_id = None
        self.messages = []
        self.last_doc_types = []
        self.intent_type = None

    @classmethod
    async def create(cls, upload_file: List[UploadFile]=None, embedding_type='questions', doc_type="document",
                                                             conversation_id: Optional[str] = None,
                                                             messages: Optional[List[Dict]] = None,
                                                             intent_type="chat", **kwargs):
        instance = cls()
        await instance.initialize(upload_file, embedding_type, doc_type, conversation_id=conversation_id,
                                                                                      messages=messages,
                                                                                      intent_type=intent_type,
                                                                                      **kwargs)
        return instance

    async def initialize(self, upload_file: List[UploadFile]=None, embedding_type='questions', doc_type="document",
                         conversation_id: Optional[str] = None,
                         messages: Optional[List[Dict]] = None,
                         intent_type="chat", **kwargs):
        self.embedding_type = embedding_type

        self.upload_file = upload_file
        self.doc_type = doc_type
        self.intent_type=intent_type
        self.conversation_id = conversation_id  # æ–°å¢
        self.messages = messages or []
        self.question = ""
        if self.messages:
            for msg in reversed(self.messages):
                if msg.get("role") == "user":
                    self.question = msg.get("content", "").strip()
                    break
            if self.question:
                print(f"ğŸ¯ ä»messagesä¸­æå–çš„é—®é¢˜: {self.question}")

        self.embeddings = EmbeddingData(embedding_type=embedding_type)
        self.vector = VectorStore(embedding_function=self.embeddings)

        if self.messages:
            print(f"ğŸ“š æ¥æ”¶åˆ° {len(self.messages)} æ¡å†å²æ¶ˆæ¯")

        if not upload_file:
            pass
        elif len(upload_file) == 1:
            self.if_files = False
            self.file_name = upload_file[0].filename or "unknown file"
            path_obj = Path(self.file_name)

            try:
                if upload_file[0].content_type and upload_file[0].content_type.startswith('image/'):
                    content = await upload_file[0].read()
                    self.image_binary_data = content
                    # é‡ç½®æ–‡ä»¶æŒ‡é’ˆï¼Œä»¥ä¾¿ DocumentLoader å¯ä»¥è¯»å–
                    await upload_file[0].seek(0)

                document_loader = DocumentLoader(upload_file[0])
                self.target_file = await document_loader.load()
                document_loader.cleanup_temp_resources()
                if self.target_file and self.target_file[0].page_content == '':
                    self.target_file = None
                else:
                    if 'document_loader' in locals():
                        document_loader.cleanup_temp_resources()
                    self.file_type = document_loader._detect_document_type()
                    return False
            except Exception as e:
                print(f"âŒ embedding module error: {str(e)}")
                raise e
        else:
            self.if_files = True
            for f in upload_file:
                document_loader_muti_file = DocumentLoader(f)
                self.mutil_files.append(await document_loader_muti_file.load())
                document_loader_muti_file.cleanup_temp_resources()
            print(f"ğŸ¯ {self.mutil_files} ğŸ¯")

    async def llava_get_content(self, prompt_sentence, image_bytes, is_text_image, user_question=""):
        """è·å–LLaVAåˆ†æç»“æœ"""
        prompt_sentence = prompt_sentence.strip()
        print(f"ğŸŒ› is_text_image: {is_text_image}")
        print(f"ğŸŒ› ç”¨æˆ·é—®é¢˜: {user_question}")

        if not is_text_image:
            # çº¯å›¾ç‰‡æ¨¡å¼
            if user_question and user_question.strip():
                # æœ‰ç”¨æˆ·æé—®ï¼Œä½¿ç”¨é—®ç­”æ¨¡æ¿
                llava_prompt = prompt_setting.pure_image_qa_template.format(question=user_question)
                print(f"ğŸ¦ çº¯å›¾ç‰‡å¸¦é—®é¢˜æé—®æ¨¡å¼")
            else:
                # æ²¡æœ‰ç”¨æˆ·æé—®ï¼Œä½¿ç”¨æè¿°æ¨¡æ¿
                llava_prompt = prompt_sentence
                print(f"ğŸ¦ çº¯å›¾ç‰‡æè¿°æ¨¡å¼")
        else:
            # å›¾æ–‡æ··åˆæ¨¡å¼ - ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„æç¤ºè¯
            llava_prompt = prompt_sentence
            print(f"ğŸ¦ å›¾æ–‡æ··åˆåˆ†ææ¨¡å¼")

        print(f"ğŸŒ› å‘é€ç»™LLaVAçš„æç¤ºè¯é•¿åº¦: {len(llava_prompt)}")

        final_answer = await analyze_with_image(
            image_bytes=image_bytes,
            question=llava_prompt,
        )

        if isinstance(final_answer, dict) and 'content' in final_answer:
            result_content = final_answer['content'].strip()
        else:
            result_content = str(final_answer).strip()

        print(f"ğŸŒ› LLaVAè¿”å›ç»“æœé•¿åº¦: {len(result_content)}")
        return result_content

    async def analyse_image_information(self):
        """
        åˆ†æå›¾ç‰‡ä¿¡æ¯ - ç»Ÿä¸€ä½¿ç”¨messageæ•°ç»„æ¨¡å¼
        """
        try:
            image_byte_content = self.image_binary_data
            print(f"âœ… ä½¿ç”¨ç¼“å­˜çš„å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ®: {len(image_byte_content)} å­—èŠ‚")

            # è·å–æœ€åä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            user_question = ""
            if self.messages:
                for msg in reversed(self.messages):
                    if msg.get("role") == "user":
                        user_question = msg.get("content", "").strip()
                        break

            # çº¯å›¾ç‰‡
            is_pure_image = not self.target_file
            if is_pure_image:
                print("ğŸ¯ è¿›å…¥çº¯å›¾ç‰‡åˆ†æåˆ†æ”¯")

                # æƒ…å†µ1: æ— ç”¨æˆ·æé—® - ç›´æ¥è¿”å›å›¾ç‰‡æè¿°
                if not user_question or user_question.strip() == "":
                    print("ğŸ¯ çº¯å›¾ç‰‡æ— æé—®ï¼Œç›´æ¥è¿”å›æè¿°")
                    result_content = await self.llava_get_content(
                        prompt_setting.prue_image_analysis_template,
                        image_byte_content,
                        False,  # ä¸æ˜¯å›¾æ–‡æ··åˆ
                        ""  # æ— ç”¨æˆ·æé—®
                    )

                    # å°†ç»“æœæµå¼è¿”å›
                    chunks = prue_image_chunks(result_content)
                    for chunk in chunks:
                        if not chunk.strip():
                            continue
                        data = {"choices": [{"delta": {"content": chunk + " "}}]}
                        yield f"data: {json.dumps(data)}\n\n"
                        await asyncio.sleep(min(0.15, max(0.05, len(chunk) / 300)))

                    yield "data: [DONE]\n\n"
                    return

                # æƒ…å†µ2: æœ‰ç”¨æˆ·æé—® - ä½¿ç”¨messageæ•°ç»„æ¨¡å¼
                else:
                    print("ğŸ¯ çº¯å›¾ç‰‡æœ‰æé—®ï¼Œä½¿ç”¨messageæ•°ç»„æ¨¡å¼")
                    # è·å–å›¾ç‰‡åˆ†æç»“æœ
                    image_description = await self.llava_get_content(
                        prompt_setting.prue_image_analysis_template,
                        image_byte_content,
                        False,  # ä¸æ˜¯å›¾æ–‡æ··åˆ
                        user_question  # ä¼ é€’ç”¨æˆ·æé—®
                    )

                    # æ„å»ºsystemæ¶ˆæ¯
                    system_message = f"ã€å›¾ç‰‡åˆ†æç»“æœã€‘\n{image_description}\n\nè¯·æ ¹æ®å›¾ç‰‡å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"

                    # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯æ•°ç»„
                    llm_messages = [{"role": "system", "content": system_message}]

                    # æ·»åŠ å†å²æ¶ˆæ¯ï¼ˆå‰ç«¯å·²é™åˆ¶æ•°é‡ï¼‰
                    if self.messages:
                        for msg in self.messages:
                            normalized_msg = {"role": msg.get("role", "user"), "content": msg.get("content", "")}
                            if normalized_msg["content"].strip():
                                llm_messages.append(normalized_msg)

                    print(f"ğŸ”„ çº¯å›¾ç‰‡messageæ¨¡å¼: æ¶ˆæ¯æ€»æ•° {len(llm_messages)}")

                    # è°ƒç”¨æµå¼LLM
                    async for chunk in stream_llm_response(llm_messages):
                        yield chunk

                    yield "data: [DONE]\n\n"
                    return

            else:
                # ========== å›¾æ–‡å¤„ç†æ¨¡å¼ ==========
                print(f"ğŸ¦ å¼€å§‹åˆ†æå›¾æ–‡ä¿¡æ¯")

                # è·å–å›¾æ–‡åˆ†æç»“æœ
                image_description = await self.llava_get_content(
                    prompt_setting.prue_image_analysis_template,
                    image_byte_content,
                    True,  # å›¾æ–‡æ··åˆ
                    user_question if user_question else ""  # ä¼ é€’ç”¨æˆ·æé—®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                )

                # æå–OCRæ–‡æœ¬
                ocr_text = self.target_file[0].page_content if self.target_file else ""
                print(f"ğŸŒ› OCRæ–‡æœ¬é•¿åº¦: {len(ocr_text)}")

                # æ„å»ºåŸºç¡€systemæ¶ˆæ¯
                system_message_parts = []
                if image_description:
                    system_message_parts.append(f"ã€å›¾ç‰‡åˆ†æç»“æœã€‘\n{image_description}")
                if ocr_text:
                    system_message_parts.append(f"ã€OCRæ–‡æœ¬å†…å®¹ã€‘\n{ocr_text}")

                # å¦‚æœæœ‰ç”¨æˆ·æé—®ï¼Œå°è¯•æ£€ç´¢çŸ¥è¯†åº“
                if user_question and user_question.strip():
                    print(f"ğŸ¯ æœ‰ç”¨æˆ·æé—®ï¼Œè¿›è¡Œæ„å›¾åˆ†æå’ŒçŸ¥è¯†åº“æŸ¥è¯¢")
                    ''''
                         å¦‚æœæ˜¯chatæ¨¡å¼ï¼Œä¸æ¶‰åŠçŸ¥è¯†åº“æŸ¥è¯¢
                    '''

                    if self.intent_type != 'chat':
                        relevant_docs = self.vector.query_by_question_vector_with_filter(
                            question_vector=user_question,
                            doc_types=self.intent_type,
                            top_k=3
                        )

                        if relevant_docs and len(relevant_docs) > 0:
                            # æ„å»ºçŸ¥è¯†åº“ä¸Šä¸‹æ–‡
                            knowledge_context = build_simple_context(relevant_docs)
                            system_message_parts.append(f"ã€ç›¸å…³çŸ¥è¯†åº“ä¿¡æ¯ã€‘\n{knowledge_context}")
                            print(f"ğŸ¯ çŸ¥è¯†åº“æ£€ç´¢åˆ° {len(relevant_docs)} æ¡ç›¸å…³ä¿¡æ¯")

                # å¦‚æœæ²¡æœ‰ç”¨æˆ·æé—®ï¼Œç›´æ¥è¿”å›åˆ†æç»“æœ
                if not user_question or user_question.strip() == "":
                    print("ğŸ¯ æ²¡æœ‰ç”¨æˆ·é—®é¢˜ï¼Œç›´æ¥è¿”å›å›¾æ–‡åˆ†æç»“æœ")
                    combined_content = "\n\n".join(system_message_parts)

                    # å°†ç»“æœæµå¼è¿”å›
                    chunk_size = 50
                    for i in range(0, len(combined_content), chunk_size):
                        chunk = combined_content[i:i + chunk_size]
                        data = {"choices": [{"delta": {"content": chunk}}]}
                        yield f"data: {json.dumps(data)}\n\n"
                        await asyncio.sleep(0.01)

                    yield "data: [DONE]\n\n"
                    return

                # æœ‰ç”¨æˆ·æé—®ï¼Œä½¿ç”¨å®Œæ•´çš„messageæ•°ç»„æ¨¡å¼
                system_message = "\n\n".join(system_message_parts)
                system_message += "\n\nè¯·æ ¹æ®å›¾ç‰‡å†…å®¹ã€OCRæ–‡æœ¬å’Œç›¸å…³çŸ¥è¯†åº“ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"

                # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯æ•°ç»„
                llm_messages = [{"role": "system", "content": system_message}]

                # æ·»åŠ å†å²æ¶ˆæ¯
                if self.messages:
                    for msg in self.messages:
                        normalized_msg = {"role": msg.get("role", "user"), "content": msg.get("content", "")}
                        if normalized_msg["content"].strip():
                            llm_messages.append(normalized_msg)

                print(f"ğŸ”„ å›¾æ–‡messageæ¨¡å¼: systemæ¶ˆæ¯é•¿åº¦ {len(system_message)}, æ¶ˆæ¯æ€»æ•° {len(llm_messages)}")

                # è°ƒç”¨æµå¼LLM
                async for chunk in stream_llm_response(llm_messages):
                    yield chunk

                yield "data: [DONE]\n\n"

        except Exception as e:
            print(f"âŒ å›¾ç‰‡åˆ†æå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            error_data = json.dumps({"error": str(e)})
            yield f"data: {error_data}\n\n"
            yield "data: [DONE]\n\n"


    def store_document_to_vector(self, chunks, doc_type):
        try:
            print(f"ğŸš€ å…±æœ‰{len(chunks)} è¿›è¡Œä¿å­˜ï¼Œæ–‡æ¡£ç±»å‹: {doc_type}")
            for i, chunk in enumerate(chunks):
                if hasattr(chunk, 'metadata'):
                    chunk.metadata['doc_type'] = doc_type
                else:
                    chunk.metadata = {'doc_type': doc_type}
            ids = self.vector.add_document_to_vector(chunks)
            print(f" stored {self.file_name} documents successfully")
            return ids
        except Exception as e:
                print(f" stored {self.file_name} documents failed: {str(e)}")
                raise e

    def del_knowledge_item(self, ids):
        corpus_ids = self.collation_ids(ids)

        result = []
        try:
            for corpus_id in corpus_ids:
                res = self.vector.delete_document(corpus_id)
                result.append(res)

        except Exception as e:
            print(f"åˆ é™¤å¤±è´¥å‘é‡æ•°æ®åº“æ•°æ®: {str(e)}")
            raise e

        if None in result:
            return None
        else:
            return True

    def clear_all_documents(self):
        self.vector.clear_collection()

    def question_query_from_vector(self):
        """
        é€»è¾‘ï¼šç›´æ¥åŸºäºç”¨æˆ·çš„æ„å›¾åˆ†æï¼ŒåæœŸå¯èå…¥æ™ºèƒ½åˆ†æï¼Œä½†æ˜¯å¤æ‚æ€§å’Œåˆ†æè´¨é‡é—®é¢˜æœ‰å›°éš¾
        chatæ¨¡å¼ä¸æŸ¥è¯¢çŸ¥è¯†åº“ï¼Œä¸æä¾›çŸ¥è¯†åº“å†…éƒ¨ä¿¡æ¯
        """
        results = self.vector.query_by_question_vector_with_filter(
                question_vector=self.question,
                doc_types=self.intent_type,
                top_k=5  # åªéœ€è¦5ä¸ªæœ€ä¼˜ç»“æœ
            )

        if results and len(results) > 0:
            return results
        else:
            print(f"âš ï¸ è¿‡æ»¤æŸ¥è¯¢æ— ç»“æœï¼ŒçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ç±»å‹çš„å†…å®¹")
            return []

    def get_chunk_doc(self, target_file, clear_chunks=False):
        try:
            print(f"ğŸš€ start split {self.file_name}")
            splitter_chunks = TextSplitter().split_document(target_file)

            if clear_chunks:
                chunks = self.clear_data(splitter_chunks)
            else:
                chunks = splitter_chunks
            return chunks
        except Exception as e:
            print(f" split error: {e}")
            raise e

    async def stream_context_from_docs(self, documents):
        """æµå¼ç”Ÿæˆä¸Šä¸‹æ–‡ - æ­£ç¡®çš„å¤šè½®å¯¹è¯å¤„ç†"""
        # æ„å»ºæ¶ˆæ¯æ•°ç»„
        llm_messages = []

        # 1. å¦‚æœæœ‰çŸ¥è¯†åº“ä¿¡æ¯ï¼Œä½œä¸ºsystemæ¶ˆæ¯
        if documents:
            context_str = build_simple_context(documents)
            system_content =  prompt_setting.knowledge_history_template.format(context_str=context_str)
            llm_messages.append({
                "role": "system",
                "content": system_content
            })

        # 2. æ£€æŸ¥æ˜¯å¦æ˜¯æŒ‡ä»£å›¾ç‰‡çš„é—®é¢˜
        is_image_reference = False
        image_reference_text = ""

        if self.messages and len(self.messages) >= 2:
            current_question = self.question or ""
            # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡ç›¸å…³çš„æŒ‡ä»£è¯
            image_keywords = ["å›¾", "å›¾ç‰‡", "ç…§ç‰‡", "æˆªå›¾", "ç”»é¢", "å›¾åƒ", "photo", "image"]
            has_image_keyword = any(keyword in current_question for keyword in image_keywords)

            if has_image_keyword:
                # æŸ¥æ‰¾æœ€è¿‘çš„å›¾ç‰‡æè¿°
                for i in range(len(self.messages) - 2, -1, -1):  # ä»å€’æ•°ç¬¬äºŒæ¡å¾€å‰æ‰¾
                    msg = self.messages[i]
                    if isinstance(msg, dict):
                        # æ£€æŸ¥æ˜¯å¦æ˜¯assistantçš„å›å¤ä¸”åŒ…å«å›¾ç‰‡æè¿°ç‰¹å¾
                        content = msg.get("content", "")
                        if ("è¿™æ˜¯ä¸€å¼ " in content or "ç…§ç‰‡" in content or
                                "åœºæ™¯" in content or "ç”»é¢" in content):
                            is_image_reference = True
                            image_reference_text = content
                            break

        # 2. ç›´æ¥ä¼ é€’åŸå§‹å¯¹è¯å†å²ï¼ˆå‰ç«¯å·²é™åˆ¶æ•°é‡ï¼‰
        if self.messages:
            # ç¡®ä¿æ ¼å¼æ­£ç¡®
            for msg in self.messages:
                normalized_msg = {}
                # è½¬æ¢role
                if "type" in msg:
                    normalized_msg["role"] = "user" if msg["type"] == "user" else "assistant"
                elif "role" in msg:
                    normalized_msg["role"] = msg["role"]
                else:
                    normalized_msg["role"] = "user"  # é»˜è®¤

                # ç¡®ä¿contentå­˜åœ¨
                if "content" in msg:
                    normalized_msg["content"] = msg["content"]
                elif "text" in msg:
                    normalized_msg["content"] = msg["text"]
                else:
                    normalized_msg["content"] = ""

                # åªæ·»åŠ æœ‰å†…å®¹çš„message
                if normalized_msg["content"].strip():
                    llm_messages.append(normalized_msg)

        if is_image_reference and image_reference_text:
            # åœ¨æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯åæ·»åŠ ç³»ç»Ÿæç¤º
            for i in range(len(llm_messages) - 1, -1, -1):
                if llm_messages[i].get("role") == "user":
                    # ä¿®æ”¹å½“å‰ç”¨æˆ·é—®é¢˜ï¼Œæ˜ç¡®å¼•ç”¨å›¾ç‰‡æè¿°
                    original_content = llm_messages[i]["content"]
                    enhanced_content = f"""
                            {original_content}
                        ï¼ˆæç¤ºï¼šæ ¹æ®ä¹‹å‰çš„å¯¹è¯ï¼Œå›¾ç‰‡æè¿°ä¸ºï¼š{image_reference_text[:200]}...è¯·åŸºäºè¿™ä¸ªå›¾ç‰‡æè¿°å›ç­”ã€‚ï¼‰"""

                    llm_messages[i]["content"] = enhanced_content
                    break


        print(f"ğŸ”„ æ–‡æœ¬æ¨¡å¼:å¼€å§‹æµå¼ç”Ÿæˆï¼Œæ¶ˆæ¯æ€»æ•°: {len(llm_messages)}")

        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        try:
            # è°ƒç”¨æµå¼LLMï¼Œä¼ é€’æ­£ç¡®çš„messagesæ•°ç»„
            async for chunk in stream_llm_response(llm_messages):
                if chunk:
                    yield chunk

            yield "data: [DONE]\n\n"
            end_time = time.time()
            print(f"âœ… æµå¼ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")

        except Exception as e:
            print(f"âŒ æµå¼ç”Ÿæˆå¼‚å¸¸: {e}")
            error_data = json.dumps({"error": str(e)})
            yield f"data: {error_data}\n\n"
            yield "data: [DONE]\n\n"


    async def upload_infor_to_vector(self):
        try:
            if self.file_type != 'image':
                print(f" âœ… å¼€å§‹è¿›è¡Œä¿å­˜çŸ¥è¯†åº“æ“ä½œ, ä¸Šä¼ çš„çŸ¥è¯†ç±»å‹{self.doc_type}")
                chunks = self.get_chunk_doc(self.target_file)
                stored_ids = self.store_document_to_vector(chunks, self.doc_type)
                return stored_ids
            else:
                print(f"ä¸èƒ½ä¸Šä¼ å›¾ç‰‡")
                pass
        except Exception as e:
            print(f"âŒå­˜å‚¨å‘é‡æ•°æ®åº“å¤±è´¥ {str(e)}")

    def clear_data(self, chunks):
        all_rag_chunks = []

        for j, chunk in enumerate(chunks):
            cur_document = Document(
                page_content=chunk.page_content,
                metadata={
                    "source":self.file_name,
                    "chunk":j
                }
            )
            all_rag_chunks.append(cur_document)
        clearner = AdvancedTextCleaner()
        cleaned_chunks = clearner.clean_documents(all_rag_chunks)
        print(f" from {len(all_rag_chunks)} remove {len(cleaned_chunks)} ")
        return cleaned_chunks

    def collation_ids(self, ids):
        data_dict = dict(ids)
        corpus_ids = data_dict.get("corpus_ids", [])
        return corpus_ids


    def dev_env_test_api(self):
        self.vector.verify_doc_type_storage()
        # éªŒè¯ç‰¹å®šç±»å‹
        # self.vector.verify_doc_type_storage("resume")
        # self.vector.verify_doc_type_storage("code")

    def analyze_intent_with_llm(self, question):
        """
        ä½¿ç”¨LLMåˆ†æé—®é¢˜æ„å›¾ï¼Œè¿”å›å¯èƒ½çš„doc_typeæ•°ç»„
        """
        try:
            result = connect_text_llm(question)

            # ç®€åŒ–å¤„ç†ï¼šç›´æ¥æå–content
            if isinstance(result, dict):
                content = result.get('content', '')
            else:
                content = str(result)

            # å°è¯•è§£æJSON
            import json
            import re

            # æ¸…ç†content
            content = content.strip()

            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                try:
                    json_str = json_match.group()
                    content_dict = json.loads(json_str)
                    doc_types = content_dict.get('doc_types', [])
                    print(f"ğŸ¯ LLMæ„å›¾åˆ†æç»“æœ: {doc_types}")
                    return doc_types
                except json.JSONDecodeError:
                    print(f"âŒ JSONè§£æå¤±è´¥ï¼Œå†…å®¹: {content[:100]}...")

            print(f"âš ï¸ æœªèƒ½è§£ædoc_typesï¼Œè¿”å›ç©ºæ•°ç»„")
            return []

        except Exception as e:
            print(f"âŒ LLMæ„å›¾åˆ†æå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return []

    # async def run_by_web(self):
    #     print(f"ğŸš€ Rag started at {datetime.datetime.now()} ")
    #     try:
    #         loader = DocumentLoader(urls=["https://tailwindcss.com/docs/installation/using-vite"])
    #         docs = await loader.load()
    #         text = "\n".join([doc.page_content for doc in docs])
    #         chunks = TextSplitter().split_text(text)
    #         print(f" åˆ†å‰²å®Œæˆï¼Œå…±ç”Ÿæˆ {len(chunks)} ä¸ªæ–‡æœ¬å—")
    #         return chunks
    #     except Exception as e:
    #         print(f" æ‰§è¡Œå¤±è´¥: {e}")
    #         raise

    # async def main():
    #     app = RagService()
    #     res = await app.run_rag()
    #     for i, chunk in enumerate(res):
    #         print(f"--- åˆ†å— {i + 1} ---\n{chunk[:200]}...")
    #
    # asyncio.run(main())

