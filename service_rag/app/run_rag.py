from typing import Optional, List, Dict
from fastapi import UploadFile
import asyncio
import time
import json
from pathlib import Path
from service_rag.app.embedding.embedding_data import EmbeddingData
from service_rag.app.prompt.prompt import prompt_setting
from langchain_core.prompts import PromptTemplate
from langchain_core.documents import Document
from service_rag.app.document_operation.document_loader import DocumentLoader
from service_rag.app.text_splitter.text_split import TextSplitter
from service_rag.app.vector.vector_store import VectorStore
from service_rag.app.llm_model.contect_llm import  connect_text_llm, analyze_with_image, stream_llm_response
from service_rag.app.text_splitter.advanced_text_cleaner import AdvancedTextCleaner
from service_rag.app.service.gen_util import switch_correct_prompt, build_simple_context, prue_image_chunks

class RagService:
    def __init__(self):
        self.prompt = PromptTemplate(input_variables=['context', 'question'],
                                     template=prompt_setting.rag_template)
        self.embedding_type = None
        self.upload_file = None
        self.file_name = None
        self.target_file = None
        self.embeddings = None
        self.vector = None
        self.question = None
        self.file_type = None
        self.if_files = None
        self.doc_type = None
        self.mutil_files = []

        self.image_binary_data = None
        self.conversation_id = None
        self.messages = []

    @classmethod
    async def create(cls, upload_file: List[UploadFile]=None, embedding_type='questions', doc_type="document",
                                                             conversation_id: Optional[str] = None,
                                                             messages: Optional[List[Dict]] = None, **kwargs):
        instance = cls()
        await instance.initialize(upload_file, embedding_type, doc_type, conversation_id=conversation_id,
                                                                                      messages=messages,
                                                                                      **kwargs)
        return instance

    async def initialize(self, upload_file: List[UploadFile]=None, embedding_type='questions', doc_type="document",
                         conversation_id: Optional[str] = None,
                         messages: Optional[List[Dict]] = None, **kwargs):
        self.embedding_type = embedding_type

        self.upload_file = upload_file
        self.doc_type = doc_type

        self.conversation_id = conversation_id  # æ–°å¢
        self.messages = messages or []
        self.question = ""
        if self.messages:
            for msg in reversed(self.messages):
                if msg.get("role") == "user":
                    self.question = msg.get("content", "").strip()
                    break
            if self.question:
                print(f"ğŸ¯ ä»messagesä¸­æå–çš„é—®é¢˜: {self.question}")

        self.embeddings = EmbeddingData(embedding_type=embedding_type)
        self.vector = VectorStore(embedding_function=self.embeddings)

        if self.messages:
            print(f"ğŸ“š æ¥æ”¶åˆ° {len(self.messages)} æ¡å†å²æ¶ˆæ¯")

        if not upload_file:  # æ— æ–‡ä»¶
            pass
        elif len(upload_file) == 1:
            self.if_files = False
            self.file_name = upload_file[0].filename or "unknown file"
            path_obj = Path(self.file_name)

            try:
                if upload_file[0].content_type and upload_file[0].content_type.startswith('image/'):
                    content = await upload_file[0].read()
                    self.image_binary_data = content
                    # é‡ç½®æ–‡ä»¶æŒ‡é’ˆï¼Œä»¥ä¾¿ DocumentLoader å¯ä»¥è¯»å–
                    await upload_file[0].seek(0)

                document_loader = DocumentLoader(upload_file[0])
                self.target_file = await document_loader.load()
                document_loader.cleanup_temp_resources()
                print(f"ğŸš€ğŸš€ğŸš€ğŸš€{ self.target_file} ğŸš€ğŸš€")
                if self.target_file and self.target_file[0].page_content == '':
                    self.target_file = None
                else:
                    if 'document_loader' in locals():
                        document_loader.cleanup_temp_resources()
                    self.file_type = document_loader._detect_document_type()
                    return False
            except Exception as e:
                print(f"âŒ embedding module error: {str(e)}")
                raise e
        else:
            self.if_files = True
            for f in upload_file:
                document_loader_muti_file = DocumentLoader(f)
                self.mutil_files.append(await document_loader_muti_file.load())
                document_loader_muti_file.cleanup_temp_resources()
            print(f"ğŸ¯ {self.mutil_files} ğŸ¯")


    async def llava_get_content(self, prompt_sentence, image_bytes, is_text_image):
        prompt_sentence = prompt_sentence.strip()

        if self.messages and len(self.messages) > 0:
            history_text = ""
            for msg in self.messages[-5:]:  # åªå–æœ€è¿‘5æ¡æ¶ˆæ¯
                role = "ç”¨æˆ·" if msg.get("role") == "user" else "åŠ©æ‰‹"
                content = msg.get("content", "")
                history_text += f"{role}: {content}\n"

            enhanced_prompt = f"ã€å¯¹è¯å†å²ã€‘\n{history_text}\nã€å½“å‰ä»»åŠ¡ã€‘\n"
        else:
            enhanced_prompt = ""

        if not is_text_image:
            if self.question:
                llava_prompt = prompt_setting.pure_image_qa_template.format(question=self.question)
                print(f"ğŸ¦ ç”¨æˆ·æé—®: {self.question}")
            else:
                llava_prompt = prompt_sentence
                print(f"ğŸ¦ ç”¨æˆ·æœªæé—®ï¼Œè‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡æè¿°")
        else:
            llava_prompt = prompt_sentence

        # å¦‚æœæœ‰å†å²è®°å½•ï¼Œæ·»åŠ åˆ°æç¤ºè¯ä¸­
        if self.messages and len(self.messages) > 0:
            llava_prompt = enhanced_prompt + llava_prompt
            print(f"ğŸ¯ ä½¿ç”¨ä¸Šä¸‹æ–‡å¢å¼ºå›¾ç‰‡åˆ†æ")

        final_answer = await analyze_with_image(
            image_bytes=image_bytes,
            question=llava_prompt,
            messages=self.messages
        )

        if isinstance(final_answer, dict) and 'content' in final_answer:
            result_content = final_answer['content'].strip()
        else:
            result_content = str(final_answer).strip()

        return result_content

    async def analyse_image_information(self):
        """
        1. ä½¿ç”¨ä¸“ä¸šæç¤ºè¯è®©LLaVAåˆ†æå›¾ç‰‡
        2. åˆ†æç”¨æˆ·é—®é¢˜æ„å›¾
        3. æ ¹æ®æ„å›¾å†³å®šæ˜¯å¦æŸ¥è¯¢çŸ¥è¯†åº“
        4. ä½¿ç”¨ä¸“ä¸šå›¾ç‰‡é—®ç­”æ¨¡æ¿ç”Ÿæˆæœ€ç»ˆå›ç­”
        """
        try:
            print(f"ğŸ¦ å¤„ç†æ–‡ä»¶: {self.file_name}")
            image_byte_content = self.image_binary_data
            print(f"âœ… ä½¿ç”¨ç¼“å­˜çš„å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ®: {len(image_byte_content)} å­—èŠ‚")

            # è·å–å¯¹è¯å†å²
            history_str = ""
            if self.messages:
                for msg in self.messages:
                    role = "ç”¨æˆ·" if msg.get("role") == "user" else "åŠ©æ‰‹"
                    content = msg.get("content", "")
                    history_str += f"{role}: {content}\n"

            # çº¯å›¾ç‰‡
            is_pure_image = not self.target_file
            if is_pure_image:
                print("ğŸ¯ è¿›å…¥çº¯å›¾ç‰‡åˆ†æåˆ†æ”¯")
                # è·å–çº¯å›¾ç‰‡åˆ†æç»“æœ
                result_content = await self.llava_get_content(
                    prompt_setting.prue_image_analysis_template,
                    image_byte_content,
                    False
                )
                print(f"ğŸ“Š è·å–åˆ°çº¯å›¾ç‰‡åˆ†æç»“æœï¼Œé•¿åº¦: {len(result_content)}")

                if self.messages and len(self.messages) > 0:
                    # æ„å»ºå¸¦ä¸Šä¸‹æ–‡çš„æç¤ºè¯
                    conversation_prompt = prompt_setting.image_conversation_template.replace(
                        '{history}', history_str
                    ).replace(
                        '{image_analysis}', result_content
                    ).replace(
                        '{question}', self.question if self.question else "è¯·æè¿°è¿™å¼ å›¾ç‰‡"
                    )

                    # ä½¿ç”¨æ–°çš„æç¤ºè¯é‡æ–°åˆ†æ
                    enhanced_result = await self.llava_get_content(
                        conversation_prompt,
                        image_byte_content,
                        False
                    )
                    result_content = enhanced_result
                    print(f"ğŸ¯ ä½¿ç”¨ä¸Šä¸‹æ–‡å¢å¼ºåˆ†æï¼Œæ–°é•¿åº¦: {len(result_content)}")

                chunks = prue_image_chunks(result_content)
                # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæµå¼è¿”å› - ä½¿ç”¨å¼‚æ­¥æ–¹å¼
                import json
                for i, chunk in enumerate(chunks):
                    if not chunk.strip():
                        continue

                    data = {
                        "choices": [{"delta": {"content": chunk + " "}}]
                    }
                    yield f"data: {json.dumps(data)}\n\n"

                    # æ ¹æ®chunké•¿åº¦åŠ¨æ€è°ƒæ•´å»¶è¿Ÿ
                    delay = min(0.15, max(0.05, len(chunk) / 300))
                    await asyncio.sleep(delay)

                yield "data: [DONE]\n\n"
                return

            else:
                # ========== æƒ…å†µ1ï¼šå›¾æ–‡å¤„ç† ==========
                print(f"ğŸ¦ å¼€å§‹åˆ†æå›¾åƒä¿¡æ¯ï¼Œé—®é¢˜: {self.question} ğŸ¦")

                # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦è¾“å…¥æé—®ä¿¡æ¯
                analyse_text_image = await self.llava_get_content(
                    prompt_setting.rag_image_analysis_template,
                    image_byte_content,
                    True
                )

                if self.messages and len(self.messages) > 0:
                    conversation_prompt = prompt_setting.image_conversation_template.replace(
                        '{history}', history_str
                    ).replace(
                        '{image_analysis}', analyse_text_image
                    ).replace(
                        '{question}', self.question if self.question else "è¯·åˆ†æå›¾ç‰‡å†…å®¹"
                    )

                    enhanced_result = await self.llava_get_content(
                        conversation_prompt,
                        image_byte_content,
                        True
                    )
                    analyse_text_image = enhanced_result

                if not self.question or self.question.strip() == "":
                    print("ğŸ¯ æ²¡æœ‰ç”¨æˆ·é—®é¢˜ï¼Œç›´æ¥è¿”å›å›¾ç‰‡åˆ†æç»“æœ")
                    # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæµå¼è¿”å›
                    import json
                    chunk_size = 50
                    total_chunks = (len(analyse_text_image) + chunk_size - 1) // chunk_size

                    for i in range(0, len(analyse_text_image), chunk_size):
                        chunk = analyse_text_image[i:i + chunk_size]
                        data = {
                            "choices": [{"delta": {"content": chunk}}]
                        }
                        print(f"ğŸ“¤ å‘é€ç¬¬ {i // chunk_size + 1}/{total_chunks} ä¸ª chunkï¼Œé•¿åº¦: {len(chunk)}")
                        yield f"data: {json.dumps(data)}\n\n"
                        await asyncio.sleep(0.01)

                    yield "data: [DONE]\n\n"

                else:
                    print(f"ğŸ¯ æœ‰ç”¨æˆ·é—®é¢˜ï¼Œè¿›è¡Œæ„å›¾åˆ†æå’ŒçŸ¥è¯†åº“æŸ¥è¯¢")
                    image_description = analyse_text_image
                    ocr_text = self.target_file[0].page_content
                    intent_analysis_prompt = prompt_setting.image_intent_prompt.format(
                        image_description=image_description,
                        ocr_text=ocr_text
                    )
                    doc_types = self.analyze_intent_with_llm(intent_analysis_prompt)
                    print(f"ğŸˆ¶ é—®é¢˜çš„å›¾æ–‡ç±»å‹ç»“æœæ˜¯: {doc_types}")

                    if len(doc_types) > 0:
                        print(f"ğŸˆ¶ çŸ¥è¯†åº“åŒ…å«é—®é¢˜ç±»å‹ï¼Œå¼€å§‹è¿›è¡ŒçŸ¥è¯†åº“æŸ¥è¯¢")
                        relevant_docs = self.vector.query_by_question_vector_with_filter(
                            question_vector=self.question,
                            doc_types=doc_types,
                            top_k=5
                        )

                        if len(relevant_docs) > 0:
                            print(f"ğŸ¯ çŸ¥è¯†åº“æœ‰ç›¸å…³ä¿¡æ¯ï¼Œå¼€å§‹æ™ºèƒ½èåˆçŸ¥è¯†åº“ä¿¡æ¯å’Œç”¨æˆ·é—®é¢˜")
                            final_prompt_for_text_model = switch_correct_prompt(
                                self.question,
                                doc_types[0],
                                image_description,
                                relevant_docs,
                                ocr_text
                            )

                            # è®°å½•å¼€å§‹æ—¶é—´
                            start_time = time.time()
                            print(f"ğŸ”„ å¼€å§‹æµå¼ç”Ÿæˆï¼Œprompté•¿åº¦: {len(final_prompt_for_text_model)}")

                            # è°ƒç”¨æµå¼LLM
                            chunk_count = 0
                            llm_messages = self.messages.copy() if self.messages else []
                            llm_messages.append({"role": "user", "content": final_prompt_for_text_model})
                            async for chunk in stream_llm_response(llm_messages):
                                if chunk:
                                    chunk_count += 1
                                    if chunk_count % 10 == 0:  # æ¯10ä¸ªchunkæ‰“å°ä¸€æ¬¡
                                        print(f"ğŸ“¤ æµå¼LLMç¬¬ {chunk_count} ä¸ª chunk")
                                    yield chunk

                            # å‘é€ç»“æŸä¿¡å·
                            yield "data: [DONE]\n\n"
                            end_time = time.time()
                            print(f"âœ… æµå¼ç”Ÿæˆå®Œæˆï¼Œå…± {chunk_count} ä¸ª chunkï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")

                        else:
                            print(f"ğŸ¯ çŸ¥è¯†åº“æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œç›´æ¥è¿”å›å›¾ç‰‡åˆ†æç»“æœ")
                            # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæµå¼è¿”å›
                            import json
                            chunk_size = 50
                            total_chunks = (len(analyse_text_image) + chunk_size - 1) // chunk_size

                            for i in range(0, len(analyse_text_image), chunk_size):
                                chunk = analyse_text_image[i:i + chunk_size]
                                data = {
                                    "choices": [{"delta": {"content": chunk}}]
                                }
                                print(f"ğŸ“¤ å‘é€ç¬¬ {i // chunk_size + 1}/{total_chunks} ä¸ª chunkï¼Œé•¿åº¦: {len(chunk)}")
                                yield f"data: {json.dumps(data)}\n\n"
                                await asyncio.sleep(0.01)

                            yield "data: [DONE]\n\n"

                    else:
                        print(f"ğŸ¯ æ— åŒ¹é…æ–‡æ¡£ç±»å‹ï¼Œè¿”å›å›¾ç‰‡åˆ†æç»“æœ")
                        # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæµå¼è¿”å›
                        import json
                        chunk_size = 50
                        total_chunks = (len(analyse_text_image) + chunk_size - 1) // chunk_size

                        for i in range(0, len(analyse_text_image), chunk_size):
                            chunk = analyse_text_image[i:i + chunk_size]
                            data = {
                                "choices": [{"delta": {"content": chunk}}]
                            }
                            print(f"ğŸ“¤ å‘é€ç¬¬ {i // chunk_size + 1}/{total_chunks} ä¸ª chunkï¼Œé•¿åº¦: {len(chunk)}")
                            yield f"data: {json.dumps(data)}\n\n"
                            await asyncio.sleep(0.01)

                        yield "data: [DONE]\n\n"

        except Exception as e:
            import json
            print(f"âŒ å›¾ç‰‡åˆ†æå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            error_data = json.dumps({"error": str(e)})
            yield f"data: {error_data}\n\n"
            yield "data: [DONE]\n\n"


    def store_document_to_vector(self, chunks, doc_type):
        try:
            print(f"ğŸš€ å…±æœ‰{len(chunks)} è¿›è¡Œä¿å­˜ï¼Œæ–‡æ¡£ç±»å‹: {doc_type}")
            for i, chunk in enumerate(chunks):
                if hasattr(chunk, 'metadata'):
                    chunk.metadata['doc_type'] = doc_type
                else:
                    chunk.metadata = {'doc_type': doc_type}
            ids = self.vector.add_document_to_vector(chunks)
            print(f" stored {self.file_name} documents successfully")
            return ids
        except Exception as e:
                print(f" stored {self.file_name} documents failed: {str(e)}")
                raise e

    def del_knowledge_item(self, ids):
        corpus_ids = self.collation_ids(ids)

        result = []
        try:
            for corpus_id in corpus_ids:
                res = self.vector.delete_document(corpus_id)
                result.append(res)

        except Exception as e:
            print(f"åˆ é™¤å¤±è´¥å‘é‡æ•°æ®åº“æ•°æ®: {str(e)}")
            raise e

        if None in result:
            return None
        else:
            return True

    def clear_all_documents(self):
        self.vector.clear_collection()

    def question_query_from_vector(self):
        """
        æ–°é€»è¾‘ï¼šä½¿ç”¨LLMåˆ†ææ„å›¾ï¼Œç„¶åè¿›è¡Œè¿‡æ»¤æŸ¥è¯¢
        """
        print(f"ğŸ” æ‰§è¡Œå‘é‡æŸ¥è¯¢ï¼Œé—®é¢˜: '{self.question}'")

        # 1. ä½¿ç”¨LLMåˆ†ææ„å›¾
        intent_prompt = prompt_setting.intent_analysis_template.replace('{question}', self.question)
        doc_types = self.analyze_intent_with_llm(intent_prompt)

        # 2. å¦‚æœæœ‰åŒ¹é…çš„doc_typeï¼Œè¿›è¡Œè¿‡æ»¤æŸ¥è¯¢
        if doc_types and len(doc_types) > 0:
            print(f"ğŸ¯ ä½¿ç”¨è¿‡æ»¤æŸ¥è¯¢ (ç›®æ ‡åˆ†åŒº: {doc_types})")

            # ä½¿ç”¨è¿‡æ»¤æŸ¥è¯¢
            results = self.vector.query_by_question_vector_with_filter(
                question_vector=self.question,
                doc_types=doc_types,
                top_k=5  # åªéœ€è¦5ä¸ªæœ€ä¼˜ç»“æœ
            )

            if results and len(results) > 0:
                return results
            else:
                print(f"âš ï¸ è¿‡æ»¤æŸ¥è¯¢æ— ç»“æœï¼ŒçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ç±»å‹çš„å†…å®¹")
                return []
        else:
            print(f"ğŸ¯ æ— åŒ¹é…çš„æ–‡æ¡£ç±»å‹ï¼ŒçŸ¥è¯†åº“æ²¡æœ‰ç›¸å…³ä¿¡æ¯")
            return []

    def get_chunk_doc(self, target_file, clear_chunks=False):
        try:
            print(f"ğŸš€ start split {self.file_name}")
            splitter_chunks = TextSplitter().split_document(target_file)

            if clear_chunks:
                chunks = self.clear_data(splitter_chunks)
                print(f"ğŸš€ ğŸš€ ğŸš€  {chunks}")
            else:
                chunks = splitter_chunks
            return chunks
        except Exception as e:
            print(f" split error: {e}")
            raise e

    async def stream_context_from_docs(self, documents):
        """æµå¼ç”Ÿæˆä¸Šä¸‹æ–‡"""
        history_str = ""
        if self.messages:
            for msg in self.messages:
                role = "ç”¨æˆ·" if msg.get("role") == "user" else "åŠ©æ‰‹"
                content = msg.get("content", "")
                history_str += f"{role}: {content}\n"

        if not documents:
            # æ²¡æœ‰çŸ¥è¯†åº“ä¿¡æ¯ï¼Œä½¿ç”¨ no_knowledge_template
            formatter_prompt = prompt_setting.no_knowledge_template.replace(
                '{question}', self.question if self.question else ""
            )
        else:
            # æœ‰çŸ¥è¯†åº“ä¿¡æ¯
            context_str = build_simple_context(documents)

            # å¦‚æœæœ‰å†å²è®°å½•ï¼Œä½¿ç”¨ rag_template_pro
            if history_str:
                formatter_prompt = prompt_setting.rag_template_pro.replace(
                    '{history}', history_str
                ).replace(
                    '{context}', context_str
                ).replace(
                    '{question}', self.question if self.question else ""
                )
            else:
                # æ²¡æœ‰å†å²è®°å½•ï¼Œä½¿ç”¨ rag_template
                formatter_prompt = prompt_setting.rag_template.replace(
                    '{context}', context_str
                ).replace(
                    '{question}', self.question if self.question else ""
                )

        print(f"ğŸ”„ å¼€å§‹æµå¼ç”Ÿæˆï¼Œprompté•¿åº¦: {len(formatter_prompt)}")
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        try:
            llm_messages = [
                {"role": "user", "content": formatter_prompt}
            ]
            # è°ƒç”¨æµå¼LLM
            async for chunk in stream_llm_response(llm_messages):
                if chunk:
                    yield chunk
            yield "data: [DONE]\n\n"

            end_time = time.time()
            print(f"âœ… æµå¼ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")

        except Exception as e:
            print(f"âŒ æµå¼ç”Ÿæˆå¼‚å¸¸: {e}")
            error_data = json.dumps({"error": str(e)})
            yield f"data: {error_data}\n\n"
            yield "data: [DONE]\n\n"

    async def upload_infor_to_vector(self):
        try:
            if self.file_type != 'image':
                print(f" âœ… å¼€å§‹è¿›è¡Œä¿å­˜çŸ¥è¯†åº“æ“ä½œ, ä¸Šä¼ çš„çŸ¥è¯†ç±»å‹{self.doc_type}")
                chunks = self.get_chunk_doc(self.target_file)
                stored_ids = self.store_document_to_vector(chunks, self.doc_type)
                return stored_ids
            else:
                print(f"ä¸èƒ½ä¸Šä¼ å›¾ç‰‡")
                pass
        except Exception as e:
            print(f"âŒå­˜å‚¨å‘é‡æ•°æ®åº“å¤±è´¥ {str(e)}")

    def clear_data(self, chunks):
        all_rag_chunks = []

        for j, chunk in enumerate(chunks):
            cur_document = Document(
                page_content=chunk.page_content,
                metadata={
                    "source":self.file_name,
                    "chunk":j
                }
            )
            all_rag_chunks.append(cur_document)
        clearner = AdvancedTextCleaner()
        cleaned_chunks = clearner.clean_documents(all_rag_chunks)
        print(f" from {len(all_rag_chunks)} remove {len(cleaned_chunks)} ")
        return cleaned_chunks

    def collation_ids(self, ids):
        data_dict = dict(ids)
        corpus_ids = data_dict.get("corpus_ids", [])
        return corpus_ids


    def dev_env_test_api(self):
        self.vector.verify_doc_type_storage()
        # éªŒè¯ç‰¹å®šç±»å‹
        # self.vector.verify_doc_type_storage("resume")
        # self.vector.verify_doc_type_storage("code")

    def analyze_intent_with_llm(self, question):
        """
        ä½¿ç”¨LLMåˆ†æé—®é¢˜æ„å›¾ï¼Œè¿”å›å¯èƒ½çš„doc_typeæ•°ç»„
        """
        try:
            print(f"ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ä¼ è¿‡æ¥çš„é—®é¢˜æ˜¯: \n{question} ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯")
            result = connect_text_llm(question)

            # ç®€åŒ–å¤„ç†ï¼šç›´æ¥æå–content
            if isinstance(result, dict):
                content = result.get('content', '')
            else:
                content = str(result)

            # å°è¯•è§£æJSON
            import json
            import re

            # æ¸…ç†content
            content = content.strip()

            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                try:
                    json_str = json_match.group()
                    content_dict = json.loads(json_str)
                    doc_types = content_dict.get('doc_types', [])
                    print(f"ğŸ¯ LLMæ„å›¾åˆ†æç»“æœ: {doc_types}")
                    return doc_types
                except json.JSONDecodeError:
                    print(f"âŒ JSONè§£æå¤±è´¥ï¼Œå†…å®¹: {content[:100]}...")

            print(f"âš ï¸ æœªèƒ½è§£ædoc_typesï¼Œè¿”å›ç©ºæ•°ç»„")
            return []

        except Exception as e:
            print(f"âŒ LLMæ„å›¾åˆ†æå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return []

    # async def run_by_web(self):
    #     print(f"ğŸš€ Rag started at {datetime.datetime.now()} ")
    #     try:
    #         loader = DocumentLoader(urls=["https://tailwindcss.com/docs/installation/using-vite"])
    #         docs = await loader.load()
    #         text = "\n".join([doc.page_content for doc in docs])
    #         chunks = TextSplitter().split_text(text)
    #         print(f" åˆ†å‰²å®Œæˆï¼Œå…±ç”Ÿæˆ {len(chunks)} ä¸ªæ–‡æœ¬å—")
    #         return chunks
    #     except Exception as e:
    #         print(f" æ‰§è¡Œå¤±è´¥: {e}")
    #         raise

    # async def main():
    #     app = RagService()
    #     res = await app.run_rag()
    #     for i, chunk in enumerate(res):
    #         print(f"--- åˆ†å— {i + 1} ---\n{chunk[:200]}...")
    #
    # asyncio.run(main())

