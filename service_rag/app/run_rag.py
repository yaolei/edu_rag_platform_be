from typing import Optional, List
from fastapi import UploadFile
import asyncio
import time
import base64
import json
from pathlib import Path
from service_rag.app.embedding.embedding_data import EmbeddingData
from service_rag.app.prompt.prompt import prompt_setting
from langchain_core.prompts import PromptTemplate
from langchain_core.documents import Document
from service_rag.app.document_operation.document_loader import DocumentLoader
from service_rag.app.text_splitter.text_split import TextSplitter
from service_rag.app.vector.vector_store import VectorStore
from service_rag.app.llm_model.contect_llm import  connect_text_llm, analyze_with_image, stream_llm_response
from service_rag.app.text_splitter.advanced_text_cleaner import AdvancedTextCleaner
from service_rag.app.service.gen_util import switch_correct_prompt, build_simple_context


class RagService:
    def __init__(self):
        self.prompt = PromptTemplate(input_variables=['context', 'question'],
                                     template=prompt_setting.rag_template)
        self.embedding_type = None
        self.upload_file = None
        self.file_name = None
        self.file_name_without_extension = None
        self.target_file = None
        self.embeddings = None
        self.vector = None
        self.question = None
        self.file_type = None
        self.if_files = None
        self.doc_type = None
        self.mutil_files = []

    @classmethod
    async def create(cls, upload_file: List[UploadFile]=None, embedding_type='questions', doc_type="document",
                     question:Optional[str] = None, **kwargs):
        instance = cls()
        await instance.initialize(upload_file, embedding_type, doc_type, question, **kwargs)
        return instance

    async def initialize(self, upload_file: List[UploadFile]=None, embedding_type='questions', doc_type="document",
                         question:Optional[str] = None, **kwargs):
        self.embedding_type = embedding_type
        self.question = question
        self.upload_file = upload_file
        self.doc_type = doc_type
        self.embeddings = EmbeddingData(embedding_type=embedding_type)
        self.vector = VectorStore(embedding_function=self.embeddings)
        if not upload_file:  # æ— æ–‡ä»¶
            pass
        elif len(upload_file) == 1:
            self.if_files = False
            self.file_name = upload_file[0].filename or "unknown file"
            path_obj = Path(self.file_name)
            self.file_name_without_extension = path_obj.stem

            try:
                document_loader = DocumentLoader(upload_file[0])
                self.target_file = await document_loader.load()
                document_loader.cleanup_temp_resources()
                print(f"ğŸš€ğŸš€ğŸš€ğŸš€{ self.target_file} ğŸš€ğŸš€")
                if self.target_file and self.target_file[0].page_content == '':
                    self.target_file = None
                else:
                    if 'document_loader' in locals():
                        document_loader.cleanup_temp_resources()
                    self.file_type = document_loader._detect_document_type()
                    return False
            except Exception as e:
                print(f"âŒ embedding module error: {str(e)}")
                raise e
        else:
            self.if_files = True
            for f in upload_file:
                document_loader_muti_file = DocumentLoader(f)
                self.mutil_files.append(await document_loader_muti_file.load())
                document_loader_muti_file.cleanup_temp_resources()
            print(f"ğŸ¯ {self.mutil_files} ğŸ¯")


    async def llava_get_content(self, prompt_sentence, image_rul, is_text_image):
        prompt_sentence = prompt_sentence.strip()
        llaiva_prompt = ""
        if not is_text_image:
            if self.question:
                llaiva_prompt = prompt_setting.pure_image_qa_template.format(question=self.question)
                print(f"ğŸ¦ ç”¨æˆ·æé—®: {llaiva_prompt[:100]}...")
            else:
                llaiva_prompt = prompt_sentence
                print(f"ğŸ¦ ç”¨æˆ·æœªæé—®ï¼Œè‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡æè¿°")
        else:
            llaiva_prompt = prompt_sentence

        final_answer = await analyze_with_image(
            image_base64_data_url=image_rul,
            question=llaiva_prompt
        )

        if isinstance(final_answer, dict) and 'content' in final_answer:
            result_content = final_answer['content'].strip()
        else:
            result_content = str(final_answer).strip()

        return result_content

    async def analyse_image_information(self):
        """
        1. ä½¿ç”¨ä¸“ä¸šæç¤ºè¯è®©LLaVAåˆ†æå›¾ç‰‡
        2. åˆ†æç”¨æˆ·é—®é¢˜æ„å›¾
        3. æ ¹æ®æ„å›¾å†³å®šæ˜¯å¦æŸ¥è¯¢çŸ¥è¯†åº“
        4. ä½¿ç”¨ä¸“ä¸šå›¾ç‰‡é—®ç­”æ¨¡æ¿ç”Ÿæˆæœ€ç»ˆå›ç­”
        """
        try:
            # 0. ç›´æ¥è¯»å–å›¾ç‰‡æ–‡ä»¶
            upload_file = self.upload_file[0]
            content = await upload_file.read()
            base64_str = base64.b64encode(content).decode("utf-8")
            image_data_url = f"data:{upload_file.content_type};base64,{base64_str}"
            print(f"ğŸ¦ å¤„ç†æ–‡ä»¶: {upload_file.filename}")

            # çº¯å›¾ç‰‡
            is_pure_image = not self.target_file
            if is_pure_image:
                print("ğŸ¯ è¿›å…¥çº¯å›¾ç‰‡åˆ†æåˆ†æ”¯")
                # è·å–çº¯å›¾ç‰‡åˆ†æç»“æœ
                result_content = await self.llava_get_content(
                    prompt_setting.prue_image_analysis_template,
                    image_data_url,
                    False
                )
                print(f"ğŸ“Š è·å–åˆ°çº¯å›¾ç‰‡åˆ†æç»“æœï¼Œé•¿åº¦: {len(result_content)}")

                import re

                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŒ‰ä¸­æ–‡æ ‡ç‚¹åˆ†å‰²å¥å­
                sentences = re.split(r'([ã€‚ï¼ï¼Ÿï¼›\.!?;])', result_content)

                # é‡æ–°ç»„åˆå¥å­ï¼Œä¿ç•™æ ‡ç‚¹
                chunks = []
                current_chunk = ""

                for i in range(0, len(sentences), 2):
                    if i + 1 < len(sentences):
                        sentence = sentences[i] + sentences[i + 1]
                    else:
                        sentence = sentences[i]

                    # å¦‚æœå½“å‰chunkä¸ºç©ºæˆ–å¥å­å¾ˆçŸ­ï¼Œç›´æ¥æ·»åŠ 
                    if not current_chunk or len(sentence.strip()) < 10:
                        current_chunk += sentence
                    else:
                        # å¦‚æœå¥å­åŒ…å«æ¢è¡Œç¬¦ï¼Œè¯´æ˜æ˜¯æ®µè½åˆ†éš”
                        if '\n' in sentence:
                            if current_chunk:
                                chunks.append(current_chunk.strip())
                            current_chunk = sentence
                        # å¦‚æœå¥å­è¾ƒé•¿ï¼Œå•ç‹¬ä½œä¸ºä¸€ä¸ªchunk
                        elif len(sentence.strip()) > 30:
                            if current_chunk:
                                chunks.append(current_chunk.strip())
                            chunks.append(sentence.strip())
                            current_chunk = ""
                        # å¦åˆ™åˆå¹¶åˆ°å½“å‰chunk
                        else:
                            current_chunk += sentence

                if current_chunk.strip():
                    chunks.append(current_chunk.strip())

                # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæµå¼è¿”å› - ä½¿ç”¨å¼‚æ­¥æ–¹å¼
                import json
                for i, chunk in enumerate(chunks):
                    if not chunk.strip():
                        continue

                    data = {
                        "choices": [{"delta": {"content": chunk + " "}}]
                    }
                    yield f"data: {json.dumps(data)}\n\n"

                    # æ ¹æ®chunké•¿åº¦åŠ¨æ€è°ƒæ•´å»¶è¿Ÿ
                    delay = min(0.15, max(0.05, len(chunk) / 300))
                    await asyncio.sleep(delay)

                yield "data: [DONE]\n\n"
                return

            else:
                # ========== æƒ…å†µ1ï¼šå›¾æ–‡å¤„ç† ==========
                print(f"ğŸ¦ å¼€å§‹åˆ†æå›¾åƒä¿¡æ¯ï¼Œé—®é¢˜: {self.question} ğŸ¦")

                # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦è¾“å…¥æé—®ä¿¡æ¯
                analyse_text_image = await self.llava_get_content(
                    prompt_setting.rag_image_analysis_template,
                    image_data_url,
                    True
                )

                if not self.question or self.question.strip() == "":
                    print("ğŸ¯ æ²¡æœ‰ç”¨æˆ·é—®é¢˜ï¼Œç›´æ¥è¿”å›å›¾ç‰‡åˆ†æç»“æœ")
                    # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæµå¼è¿”å›
                    import json
                    chunk_size = 50
                    total_chunks = (len(analyse_text_image) + chunk_size - 1) // chunk_size

                    for i in range(0, len(analyse_text_image), chunk_size):
                        chunk = analyse_text_image[i:i + chunk_size]
                        data = {
                            "choices": [{"delta": {"content": chunk}}]
                        }
                        print(f"ğŸ“¤ å‘é€ç¬¬ {i // chunk_size + 1}/{total_chunks} ä¸ª chunkï¼Œé•¿åº¦: {len(chunk)}")
                        yield f"data: {json.dumps(data)}\n\n"
                        await asyncio.sleep(0.01)

                    yield "data: [DONE]\n\n"

                else:
                    print(f"ğŸ¯ æœ‰ç”¨æˆ·é—®é¢˜ï¼Œè¿›è¡Œæ„å›¾åˆ†æå’ŒçŸ¥è¯†åº“æŸ¥è¯¢")
                    image_description = analyse_text_image
                    ocr_text = self.target_file[0].page_content
                    intent_analysis_prompt = prompt_setting.image_intent_prompt.format(
                        image_description=image_description,
                        ocr_text=ocr_text
                    )
                    doc_types = self.analyze_intent_with_llm(intent_analysis_prompt)
                    print(f"ğŸˆ¶ é—®é¢˜çš„å›¾æ–‡ç±»å‹ç»“æœæ˜¯: {doc_types}")

                    if len(doc_types) > 0:
                        print(f"ğŸˆ¶ çŸ¥è¯†åº“åŒ…å«é—®é¢˜ç±»å‹ï¼Œå¼€å§‹è¿›è¡ŒçŸ¥è¯†åº“æŸ¥è¯¢")
                        relevant_docs = self.vector.query_by_question_vector_with_filter(
                            question_vector=self.question,
                            doc_types=doc_types,
                            top_k=5
                        )

                        if len(relevant_docs) > 0:
                            print(f"ğŸ¯ çŸ¥è¯†åº“æœ‰ç›¸å…³ä¿¡æ¯ï¼Œå¼€å§‹æ™ºèƒ½èåˆçŸ¥è¯†åº“ä¿¡æ¯å’Œç”¨æˆ·é—®é¢˜")
                            final_prompt_for_text_model = switch_correct_prompt(
                                self.question,
                                doc_types[0],
                                image_description,
                                relevant_docs,
                                ocr_text
                            )

                            # è®°å½•å¼€å§‹æ—¶é—´
                            start_time = time.time()
                            print(f"ğŸ”„ å¼€å§‹æµå¼ç”Ÿæˆï¼Œprompté•¿åº¦: {len(final_prompt_for_text_model)}")

                            # è°ƒç”¨æµå¼LLM
                            chunk_count = 0
                            async for chunk in stream_llm_response(final_prompt_for_text_model):
                                if chunk:
                                    chunk_count += 1
                                    if chunk_count % 10 == 0:  # æ¯10ä¸ªchunkæ‰“å°ä¸€æ¬¡
                                        print(f"ğŸ“¤ æµå¼LLMç¬¬ {chunk_count} ä¸ª chunk")
                                    yield chunk

                            # å‘é€ç»“æŸä¿¡å·
                            yield "data: [DONE]\n\n"
                            end_time = time.time()
                            print(f"âœ… æµå¼ç”Ÿæˆå®Œæˆï¼Œå…± {chunk_count} ä¸ª chunkï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")

                        else:
                            print(f"ğŸ¯ çŸ¥è¯†åº“æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œç›´æ¥è¿”å›å›¾ç‰‡åˆ†æç»“æœ")
                            # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæµå¼è¿”å›
                            import json
                            chunk_size = 50
                            total_chunks = (len(analyse_text_image) + chunk_size - 1) // chunk_size

                            for i in range(0, len(analyse_text_image), chunk_size):
                                chunk = analyse_text_image[i:i + chunk_size]
                                data = {
                                    "choices": [{"delta": {"content": chunk}}]
                                }
                                print(f"ğŸ“¤ å‘é€ç¬¬ {i // chunk_size + 1}/{total_chunks} ä¸ª chunkï¼Œé•¿åº¦: {len(chunk)}")
                                yield f"data: {json.dumps(data)}\n\n"
                                await asyncio.sleep(0.01)

                            yield "data: [DONE]\n\n"

                    else:
                        print(f"ğŸ¯ æ— åŒ¹é…æ–‡æ¡£ç±»å‹ï¼Œè¿”å›å›¾ç‰‡åˆ†æç»“æœ")
                        # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæµå¼è¿”å›
                        import json
                        chunk_size = 50
                        total_chunks = (len(analyse_text_image) + chunk_size - 1) // chunk_size

                        for i in range(0, len(analyse_text_image), chunk_size):
                            chunk = analyse_text_image[i:i + chunk_size]
                            data = {
                                "choices": [{"delta": {"content": chunk}}]
                            }
                            print(f"ğŸ“¤ å‘é€ç¬¬ {i // chunk_size + 1}/{total_chunks} ä¸ª chunkï¼Œé•¿åº¦: {len(chunk)}")
                            yield f"data: {json.dumps(data)}\n\n"
                            await asyncio.sleep(0.01)

                        yield "data: [DONE]\n\n"

        except Exception as e:
            import json
            print(f"âŒ å›¾ç‰‡åˆ†æå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            error_data = json.dumps({"error": str(e)})
            yield f"data: {error_data}\n\n"
            yield "data: [DONE]\n\n"


    def store_document_to_vector(self, chunks, doc_type):
        try:
            print(f"ğŸš€ å…±æœ‰{len(chunks)} è¿›è¡Œä¿å­˜ï¼Œæ–‡æ¡£ç±»å‹: {doc_type}")
            for i, chunk in enumerate(chunks):
                if hasattr(chunk, 'metadata'):
                    chunk.metadata['doc_type'] = doc_type
                else:
                    chunk.metadata = {'doc_type': doc_type}
            ids = self.vector.add_document_to_vector(chunks)
            print(f" stored {self.file_name_without_extension} documents successfully")
            return ids
        except Exception as e:
                print(f" stored {self.file_name_without_extension} documents failed: {str(e)}")
                raise e

    def del_knowledge_item(self, ids):
        corpus_ids = self.collation_ids(ids)

        result = []
        try:
            for corpus_id in corpus_ids:
                res = self.vector.delete_document(corpus_id)
                result.append(res)

        except Exception as e:
            print(f"åˆ é™¤å¤±è´¥å‘é‡æ•°æ®åº“æ•°æ®: {str(e)}")
            raise e

        if None in result:
            return None
        else:
            return True

    def clear_all_documents(self):
        self.vector.clear_collection()

    def question_query_from_vector(self):
        """
        æ–°é€»è¾‘ï¼šä½¿ç”¨LLMåˆ†ææ„å›¾ï¼Œç„¶åè¿›è¡Œè¿‡æ»¤æŸ¥è¯¢
        """
        print(f"ğŸ” æ‰§è¡Œå‘é‡æŸ¥è¯¢ï¼Œé—®é¢˜: '{self.question}'")

        # 1. ä½¿ç”¨LLMåˆ†ææ„å›¾
        doc_types = self.analyze_intent_with_llm(self.question)

        # 2. å¦‚æœæœ‰åŒ¹é…çš„doc_typeï¼Œè¿›è¡Œè¿‡æ»¤æŸ¥è¯¢
        if doc_types and len(doc_types) > 0:
            print(f"ğŸ¯ ä½¿ç”¨è¿‡æ»¤æŸ¥è¯¢ (ç›®æ ‡åˆ†åŒº: {doc_types})")

            # ä½¿ç”¨è¿‡æ»¤æŸ¥è¯¢
            results = self.vector.query_by_question_vector_with_filter(
                question_vector=self.question,
                doc_types=doc_types,
                top_k=5  # åªéœ€è¦5ä¸ªæœ€ä¼˜ç»“æœ
            )

            if results and len(results) > 0:
                return results
            else:
                print(f"âš ï¸ è¿‡æ»¤æŸ¥è¯¢æ— ç»“æœï¼ŒçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ç±»å‹çš„å†…å®¹")
                return []
        else:
            print(f"ğŸ¯ æ— åŒ¹é…çš„æ–‡æ¡£ç±»å‹ï¼ŒçŸ¥è¯†åº“æ²¡æœ‰ç›¸å…³ä¿¡æ¯")
            return []

    def get_chunk_doc(self, target_file, clear_chunks=False):
        try:
            print(f"ğŸš€ start split {self.file_name_without_extension}")
            splitter_chunks = TextSplitter().split_document(target_file)

            if clear_chunks:
                chunks = self.clear_data(splitter_chunks)
                print(f"ğŸš€ ğŸš€ ğŸš€  {chunks}")
            else:
                chunks = splitter_chunks
            return chunks
        except Exception as e:
            print(f" split error: {e}")
            raise e

    async def stream_context_from_docs(self, documents):
        """æµå¼ç”Ÿæˆä¸Šä¸‹æ–‡"""
        if not documents:
            formatter_prompt = prompt_setting.no_knowledge_template.replace(
                '{question}', self.question
            )
        else:
            context_str = build_simple_context(documents)
            formatter_prompt = prompt_setting.rag_template_pro.replace(
                '{context}', context_str
            ).replace(
                '{question}', self.question
            )

        print(f"ğŸ”„ å¼€å§‹æµå¼ç”Ÿæˆï¼Œprompté•¿åº¦: {len(formatter_prompt)}")

        try:
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()

            # è°ƒç”¨æµå¼LLM
            async for chunk in stream_llm_response(formatter_prompt):
                if chunk:
                    yield chunk

            # å‘é€ç»“æŸä¿¡å·
            yield "data: [DONE]\n\n"

            end_time = time.time()
            print(f"âœ… æµå¼ç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")

        except Exception as e:
            print(f"âŒ æµå¼ç”Ÿæˆå¼‚å¸¸: {e}")
            error_data = json.dumps({"error": str(e)})
            yield f"data: {error_data}\n\n"
            yield "data: [DONE]\n\n"

    async def upload_infor_to_vector(self):
        try:
            if self.file_type != 'image':
                print(f" âœ… å¼€å§‹è¿›è¡Œä¿å­˜çŸ¥è¯†åº“æ“ä½œ, ä¸Šä¼ çš„çŸ¥è¯†ç±»å‹{self.doc_type}")
                chunks = self.get_chunk_doc(self.target_file)
                stored_ids = self.store_document_to_vector(chunks, self.doc_type)
                return stored_ids
            else:
                print(f"ä¸èƒ½ä¸Šä¼ å›¾ç‰‡")
                pass
        except Exception as e:
            print(f"âŒå­˜å‚¨å‘é‡æ•°æ®åº“å¤±è´¥ {str(e)}")


    def clear_data(self, chunks):
        all_rag_chunks = []

        for j, chunk in enumerate(chunks):
            cur_document = Document(
                page_content=chunk.page_content,
                metadata={
                    "source":self.file_name,
                    "chunk":j
                }
            )
            all_rag_chunks.append(cur_document)
        clearner = AdvancedTextCleaner()
        cleaned_chunks = clearner.clean_documents(all_rag_chunks)
        print(f" from {len(all_rag_chunks)} remove {len(cleaned_chunks)} ")
        return cleaned_chunks

    def collation_ids(self, ids):
        data_dict = dict(ids)
        corpus_ids = data_dict.get("corpus_ids", [])
        return corpus_ids


    def dev_env_test_api(self):
        self.vector.verify_doc_type_storage()
        # éªŒè¯ç‰¹å®šç±»å‹
        # self.vector.verify_doc_type_storage("resume")
        # self.vector.verify_doc_type_storage("code")

    def analyze_intent_with_llm(self, question):
        """
        ä½¿ç”¨LLMåˆ†æé—®é¢˜æ„å›¾ï¼Œè¿”å›å¯èƒ½çš„doc_typeæ•°ç»„
        """
        try:
            # ä½¿ç”¨prompt.pyä¸­çš„æ„å›¾åˆ†ææ¨¡æ¿
            intent_prompt = prompt_setting.intent_analysis_template.replace('{question}', question)

            # ç›´æ¥ä¼ é€’å­—ç¬¦ä¸²å‚æ•°, ä½¿ç”¨å°å‹æ¨¡å‹æŸ¥è¯¢æ„å›¾
            result = connect_text_llm(intent_prompt)
            # å¤„ç†è¿”å›ç»“æœ
            content_dict = {}
            if isinstance(result, dict):
                content = result.get('content', '')
                if isinstance(content, dict):
                    content_dict = content
                elif isinstance(content, str):
                    # å°è¯•è§£æå­—ç¬¦ä¸²ä¸ºå­—å…¸
                    import json
                    try:
                        content_dict = json.loads(content)
                    except json.JSONDecodeError:
                        # å¦‚æœä¸æ˜¯JSONï¼Œå°è¯•æå–JSON
                        import re
                        json_match = re.search(r'\{.*\}', content, re.DOTALL)
                        if json_match:
                            try:
                                content_dict = json.loads(json_match.group())
                            except:
                                pass

            # ä»content_dictä¸­æå–doc_types
            if isinstance(content_dict, dict) and 'doc_types' in content_dict:
                doc_types = content_dict['doc_types']
                print(f"ğŸ¯ LLMæ„å›¾åˆ†æç»“æœ: {doc_types}")
                return doc_types

            return []

        except Exception as e:
            print(f"âŒ LLMæ„å›¾åˆ†æå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return []

    # async def run_by_web(self):
    #     print(f"ğŸš€ Rag started at {datetime.datetime.now()} ")
    #     try:
    #         loader = DocumentLoader(urls=["https://tailwindcss.com/docs/installation/using-vite"])
    #         docs = await loader.load()
    #         text = "\n".join([doc.page_content for doc in docs])
    #         chunks = TextSplitter().split_text(text)
    #         print(f" åˆ†å‰²å®Œæˆï¼Œå…±ç”Ÿæˆ {len(chunks)} ä¸ªæ–‡æœ¬å—")
    #         return chunks
    #     except Exception as e:
    #         print(f" æ‰§è¡Œå¤±è´¥: {e}")
    #         raise

    # async def main():
    #     app = RagService()
    #     res = await app.run_rag()
    #     for i, chunk in enumerate(res):
    #         print(f"--- åˆ†å— {i + 1} ---\n{chunk[:200]}...")
    #
    # asyncio.run(main())

