import requests
from service_rag.app.config.config import setting


def connect_baidu_llm(question:str, prompt:str=""):
    print(f" ä¼ è¿‡æ¥çš„é—®é¢˜æ˜¯ğŸ”¥ğŸ˜‚ğŸ˜‚ {question} ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚")
    url = setting.CHAT_URL_TEMPLATE
    payload = {
        "model": "@cf/meta/llama-3.1-8b-instruct",
        "messages": [{
        "role": "user",
        "content": question +" "+prompt
    }]}

    r = requests.post(url, json=payload, headers={"Content-Type": "application/json", "Authorization": f"Bearer {setting.TOKEN_URL}"})

    print(f"ç»“æœæ˜¯ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€{r.json()} ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€")
    body = r.json()
    if 'error_code' in body:
        print("[ERNIE ERROR]", body)
        raise RuntimeError(f"ERNIE API:{body['error_code']} {body.get('error_msg', '')}")
    #
    return {
        "role": body.get('choices', [{}])[0].get('message', {}).get('role', ''),
        "content": body.get('choices', [{}])[0].get('message', {}).get('content', '')
    }

